{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsVMOH+ib5EkEmO+U5ST4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadnyd/Synapses-25/blob/main/model2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xmCa7B3PTna-"
      },
      "outputs": [],
      "source": [
        "!pip install datasets scikit-learn matplotlib seaborn -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlHSFmljT0Lw",
        "outputId": "58387bc0-5ca5-4aaf-8ec9-ca8a56fcabe5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `apr25` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `apr25`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, log_loss, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "xSL3BZLWT2zl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading ---\n",
        "def load_criteo_data():\n",
        "    \"\"\"Loads the Criteo Uplift Prediction dataset.\"\"\"\n",
        "    print(\"Loading Criteo dataset...\")\n",
        "    # Using a smaller subset for faster demonstration if needed.\n",
        "    # Remove split='train[:1%]' for full dataset.\n",
        "    try:\n",
        "         # ds = load_dataset(\"criteo/criteo-uplift\", split='train[:5%]') # Load a subset for speed\n",
        "         ds = load_dataset(\"criteo/criteo-uplift\", split='train') # Load full dataset\n",
        "         print(\"Dataset loaded successfully.\")\n",
        "         return ds.to_pandas()\n",
        "    except Exception as e:\n",
        "         print(f\"Error loading dataset: {e}\")\n",
        "         print(\"Please ensure the 'datasets' library is installed and you have internet access.\")\n",
        "         return None\n",
        "\n",
        "def get_feature_columns():\n",
        "    \"\"\"Returns the list of feature column names.\"\"\"\n",
        "    return [f'f{i}' for i in range(12)]"
      ],
      "metadata": {
        "id": "QYcO728ZUC1C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 2. Preprocessing and Sanity Checks ---\n",
        "def normalize_features(df_train, df_test, features):\n",
        "    \"\"\"Normalizes features using StandardScaler.\"\"\"\n",
        "    print(\"Normalizing features...\")\n",
        "    scaler = StandardScaler()\n",
        "    df_train[features] = scaler.fit_transform(df_train[features])\n",
        "    df_test[features] = scaler.transform(df_test[features])\n",
        "    print(\"Features normalized.\")\n",
        "    return df_train, df_test"
      ],
      "metadata": {
        "id": "7bXouRJ5UHZe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def check_treatment_independence(X, T, test_size=0.3, random_state=42):\n",
        "    \"\"\"\n",
        "    Performs a Classifier Two-Sample Test (C2ST) to check T independence from X.\n",
        "    Trains a classifier to predict Treatment (T) from Features (X).\n",
        "    If AUC is close to 0.5, it suggests independence (cannot distinguish groups based on X).\n",
        "    \"\"\"\n",
        "    print(\"Performing C2ST for treatment independence check...\")\n",
        "    X_train, X_test, T_train, T_test = train_test_split(X, T, test_size=test_size, stratify=T, random_state=random_state)\n",
        "\n",
        "    # Use a simple model like Logistic Regression\n",
        "    model = LogisticRegression(solver='liblinear', random_state=random_state)\n",
        "    model.fit(X_train, T_train)\n",
        "\n",
        "    T_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(T_test, T_pred_proba)\n",
        "\n",
        "    # Baseline accuracy (predicting the majority class)\n",
        "    majority_class_fraction = T.mean() if T.mean() > 0.5 else 1 - T.mean()\n",
        "\n",
        "    print(f\"C2ST Classifier AUC: {auc:.4f}\")\n",
        "    print(f\"Baseline (Majority Class) Accuracy: {majority_class_fraction:.4f}\")\n",
        "\n",
        "    if abs(auc - 0.5) < 0.05: # Threshold can be adjusted\n",
        "        print(\"C2ST Result: Treatment assignment appears independent of features (AUC close to 0.5).\")\n",
        "    else:\n",
        "        print(\"C2ST Result: Treatment assignment might depend on features (AUC differs from 0.5). Caution advised.\")\n",
        "    return auc"
      ],
      "metadata": {
        "id": "HIpk91WGUMqO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Uplift Modeling Approaches ---\n",
        "\n",
        "def two_model_approach(X_train, X_test, y_train, y_test, T_train, T_test, features, target_column):\n",
        "    \"\"\"\n",
        "    Implements the Two-Model uplift approach.\n",
        "    Trains separate models for treated and control groups.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Running Two-Model Approach for {target_column} ---\")\n",
        "\n",
        "    # Separate data based on treatment status IN THE TRAINING SET\n",
        "    X_train_T = X_train[T_train == 1]\n",
        "    y_train_T = y_train[T_train == 1]\n",
        "    X_train_C = X_train[T_train == 0]\n",
        "    y_train_C = y_train[T_train == 0]\n",
        "\n",
        "    print(f\"Training set sizes: Treated={len(X_train_T)}, Control={len(X_train_C)}\")\n",
        "    if len(X_train_T) == 0 or len(X_train_C) == 0:\n",
        "        print(\"Error: Training data missing for one treatment group.\")\n",
        "        return None, None\n",
        "\n",
        "    # Train model on Treated group\n",
        "    model_T = LogisticRegression(solver='liblinear', random_state=42)\n",
        "    model_T.fit(X_train_T[features], y_train_T)\n",
        "\n",
        "    # Train model on Control group\n",
        "    model_C = LogisticRegression(solver='liblinear', random_state=42)\n",
        "    model_C.fit(X_train_C[features], y_train_C)\n",
        "\n",
        "    # Predict probabilities on the ENTIRE test set using BOTH models\n",
        "    p_T = model_T.predict_proba(X_test[features])[:, 1]\n",
        "    p_C = model_C.predict_proba(X_test[features])[:, 1]\n",
        "\n",
        "    # Calculate uplift score for EACH individual in the test set\n",
        "    uplift_score = p_T - p_C\n",
        "\n",
        "    # Prepare results dataframe including uplift scores and actuals\n",
        "    results_df = X_test.copy()\n",
        "    results_df['p_T'] = p_T\n",
        "    results_df['p_C'] = p_C\n",
        "    results_df['uplift_score'] = uplift_score\n",
        "    results_df[target_column] = y_test # Add actual outcome\n",
        "    results_df['treatment'] = T_test   # Add actual treatment\n",
        "\n",
        "    print(\"Two-Model approach finished.\")\n",
        "    return uplift_score, results_df"
      ],
      "metadata": {
        "id": "4owR-cXEUQ-e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def revert_label_approach(X_train, X_test, y_train, y_test, T_train, T_test, features, target_column):\n",
        "    \"\"\"\n",
        "    Implements the Revert Label / Class Transformation approach.\n",
        "    Transforms the target based on treatment and outcome, trains one model.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Running Revert-Label Approach for {target_column} ---\")\n",
        "\n",
        "    # Create the transformed target variable Z\n",
        "    # Z = 1 if (T=1 and Y=1) OR (T=0 and Y=0)\n",
        "    # Z = 0 otherwise\n",
        "    Z_train = np.zeros_like(y_train)\n",
        "    Z_train[ (T_train == 1) & (y_train == 1) ] = 1\n",
        "    Z_train[ (T_train == 0) & (y_train == 0) ] = 1\n",
        "\n",
        "    # Train a single model to predict Z\n",
        "    model_Z = LogisticRegression(solver='liblinear', random_state=42)\n",
        "    model_Z.fit(X_train[features], Z_train)\n",
        "\n",
        "    # Predict P(Z=1|X) on the ENTIRE test set\n",
        "    p_Z = model_Z.predict_proba(X_test[features])[:, 1]\n",
        "\n",
        "    # Calculate uplift score using the formula from the paper (adjust if needed for severe imbalance)\n",
        "    # Uplift = P(Y=1|T=1) - P(Y=1|T=0) = 2 * P(Z=1|X) - 1\n",
        "    uplift_score = 2 * p_Z - 1\n",
        "\n",
        "    # Prepare results dataframe including uplift scores and actuals\n",
        "    results_df = X_test.copy()\n",
        "    results_df['p_Z'] = p_Z\n",
        "    results_df['uplift_score'] = uplift_score\n",
        "    results_df[target_column] = y_test # Add actual outcome\n",
        "    results_df['treatment'] = T_test   # Add actual treatment\n",
        "\n",
        "    print(\"Revert-Label approach finished.\")\n",
        "    return uplift_score, results_df"
      ],
      "metadata": {
        "id": "ZNfFSyx_UU-N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Evaluation ---\n",
        "\n",
        "def calculate_qini_auuc(results_df, target_column):\n",
        "    \"\"\"\n",
        "    Calculates Qini curve, Qini coefficient, Uplift curve, and AUUC.\n",
        "\n",
        "    Args:\n",
        "        results_df (pd.DataFrame): DataFrame containing 'uplift_score',\n",
        "                                   'treatment', and the target_column (actual outcome).\n",
        "    Returns:\n",
        "        tuple: (qini_curve_df, qini_coeff, uplift_curve_df, auuc)\n",
        "    \"\"\"\n",
        "    print(\"Calculating Qini and AUUC...\")\n",
        "\n",
        "    # Sort by predicted uplift score in descending order\n",
        "    sorted_df = results_df.sort_values(by='uplift_score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    N = len(sorted_df)\n",
        "    N_T = sorted_df['treatment'].sum() # Total treated in test set\n",
        "    N_C = N - N_T                    # Total control in test set\n",
        "\n",
        "    if N_T == 0 or N_C == 0:\n",
        "        print(\"Error: Test set missing treated or control group for evaluation.\")\n",
        "        return None, 0, None, 0\n",
        "\n",
        "    # Cumulative counts and outcomes\n",
        "    sorted_df['n'] = 1 # Counter for cumulative population\n",
        "    sorted_df['cum_n'] = sorted_df['n'].cumsum()\n",
        "    sorted_df['cum_n_T'] = sorted_df['treatment'].cumsum()\n",
        "    # Ensure cum_n_C does not start at 0 to avoid division by zero\n",
        "    sorted_df['cum_n_C'] = (1 - sorted_df['treatment']).cumsum().replace(0, 1e-9) # Add small epsilon\n",
        "\n",
        "    # Cumulative outcomes for treated and control\n",
        "    sorted_df['cum_y_T'] = (sorted_df[target_column] * sorted_df['treatment']).cumsum()\n",
        "    sorted_df['cum_y_C'] = (sorted_df[target_column] * (1 - sorted_df['treatment'])).cumsum()\n",
        "\n",
        "    # --- Qini Calculation ---\n",
        "    # Incremental gain: (Responders_T) - (Responders_C * Ratio of Treated/Control seen so far)\n",
        "    # The ratio N_T / N_C in the paper's formula refers to the overall ratio in the population\n",
        "    # For the curve calculation, we use the ratio observed up to point k\n",
        "    # qini_numerator = sorted_df['cum_y_T'] - sorted_df['cum_y_C'] * (sorted_df['cum_n_T'] / sorted_df['cum_n_C'])\n",
        "    # Revised Qini based on Radcliffe 2007 and Gutierrez 2017 definition:\n",
        "    qini_numerator = sorted_df['cum_y_T'] - sorted_df['cum_y_C'] * (N_T / N_C)\n",
        "\n",
        "    # --- Uplift (AUUC) Calculation ---\n",
        "    # Difference in response rates between T and C groups seen so far\n",
        "    # Avoid division by zero if cum_n_T is zero initially\n",
        "    response_rate_T = (sorted_df['cum_y_T'] / sorted_df['cum_n_T'].replace(0, 1e-9))\n",
        "    response_rate_C = (sorted_df['cum_y_C'] / sorted_df['cum_n_C']) # Already handled division by zero\n",
        "    uplift_curve_values = (response_rate_T - response_rate_C) * (sorted_df['cum_n'] / N) # Weighted by population fraction\n",
        "\n",
        "    # Create curve dataframes\n",
        "    qini_curve_df = pd.DataFrame({\n",
        "        'population_fraction': sorted_df['cum_n'] / N,\n",
        "        'qini_value': qini_numerator\n",
        "    })\n",
        "\n",
        "    uplift_curve_df = pd.DataFrame({\n",
        "        'population_fraction': sorted_df['cum_n'] / N,\n",
        "        'uplift_value': uplift_curve_values\n",
        "    })\n",
        "\n",
        "    # Add random baseline to Qini curve\n",
        "    total_increment = qini_numerator.iloc[-1]\n",
        "    qini_curve_df['random_baseline'] = qini_curve_df['population_fraction'] * total_increment\n",
        "\n",
        "    # --- Calculate Coefficients (Area under curve) ---\n",
        "    # Use trapezoidal rule for integration\n",
        "\n",
        "    # Qini Coefficient (Normalized version sometimes used, but AUGC is common)\n",
        "    # Area under the Qini curve minus area under the random baseline\n",
        "    auqc = np.trapz(qini_curve_df['qini_value'], x=qini_curve_df['population_fraction'])\n",
        "    random_qini_area = np.trapz(qini_curve_df['random_baseline'], x=qini_curve_df['population_fraction'])\n",
        "    qini_coeff = auqc - random_qini_area # Area Between Curves\n",
        "\n",
        "    # AUUC (Area under the uplift curve)\n",
        "    auuc = np.trapz(uplift_curve_df['uplift_value'], x=uplift_curve_df['population_fraction'])\n",
        "\n",
        "    print(f\"Calculation complete: Qini Coeff = {qini_coeff:.4f}, AUUC = {auuc:.4f}\")\n",
        "    return qini_curve_df, qini_coeff, uplift_curve_df, auuc"
      ],
      "metadata": {
        "id": "Fm8eB5qyUYn2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_uplift_curves(qini_curve_df, qini_coeff, uplift_curve_df, auuc, model_name, target_column):\n",
        "    \"\"\"Plots the Qini and Uplift (AUUC) curves.\"\"\"\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Qini Curve Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(qini_curve_df['population_fraction'], qini_curve_df['qini_value'], label=f'Qini Curve ({model_name})')\n",
        "    plt.plot(qini_curve_df['population_fraction'], qini_curve_df['random_baseline'], 'k--', label='Random Baseline')\n",
        "    plt.xlabel('Proportion of Population Targeted (Sorted by Uplift)')\n",
        "    plt.ylabel('Cumulative Incremental Outcome')\n",
        "    plt.title(f'Qini Curve - {target_column.capitalize()}\\nQini Coefficient: {qini_coeff:.4f}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Uplift Curve (AUUC) Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(uplift_curve_df['population_fraction'], uplift_curve_df['uplift_value'], label=f'Uplift Curve ({model_name})')\n",
        "    plt.plot([0, 1], [0, 0], 'k--', label='Random Baseline') # Baseline for AUUC is 0\n",
        "    plt.xlabel('Proportion of Population Targeted (Sorted by Uplift)')\n",
        "    plt.ylabel('Cumulative Uplift (Avg Outcome T - Avg Outcome C)')\n",
        "    plt.title(f'Uplift Curve - {target_column.capitalize()}\\nAUUC: {auuc:.4f}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oyay2WQZUcih"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_criteo_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXF4sY9OUvUx",
        "outputId": "9ccef4eb-4da8-4907-89d4-dab378e9bcf7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Criteo dataset...\n",
            "Dataset loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = get_feature_columns()\n",
        "target_visit = 'visit'\n",
        "target_conversion = 'conversion' # Focus on conversion as in paper's later experiments\n",
        "treatment_col = 'treatment'\n",
        "\n",
        "print(\"\\n--- Data Splitting ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVB9duHFUz4q",
        "outputId": "0be56ce8-3a0a-4f29-8669-43c4715ac27d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Splitting ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Split into train/test FIRST, then apply normalization/checks\n",
        "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42, stratify=df[treatment_col]) # Stratify by treatment\n",
        "print(f\"Train set size: {len(df_train)}, Test set size: {len(df_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_05hnyNbXC9A",
        "outputId": "ef43ad12-c35d-41a9-8d8e-a9d71449cb99"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 9785714, Test set size: 4193878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # --- Preprocessing & Checks ---\n",
        "df_train, df_test = normalize_features(df_train, df_test, features)\n",
        "check_treatment_independence(df_train[features], df_train[treatment_col]) # Check on training data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFPif37FU6qb",
        "outputId": "af8b7ed0-f635-4e61-e420-986227ba088d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizing features...\n",
            "Features normalized.\n",
            "Performing C2ST for treatment independence check...\n",
            "C2ST Classifier AUC: 0.5099\n",
            "Baseline (Majority Class) Accuracy: 0.8500\n",
            "C2ST Result: Treatment assignment appears independent of features (AUC close to 0.5).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5099141126175784)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c0if6opVXCfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define common variables for models\n",
        "TARGET = target_conversion # Choose target: 'visit' or 'conversion'\n",
        "X_train = df_train[features + [treatment_col]] # Keep treatment in X for revert label logic\n",
        "y_train = df_train[TARGET]\n",
        "T_train = df_train[treatment_col]\n",
        "X_test = df_test[features + [treatment_col]] # Keep treatment info if needed, but models use features only\n",
        "y_test = df_test[TARGET]\n",
        "T_test = df_test[treatment_col]"
      ],
      "metadata": {
        "id": "cltgQksFU9-h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uplift_2M, results_2M = two_model_approach(X_train, X_test, y_train, y_test, T_train, T_test, features, TARGET)\n",
        "if results_2M is not None:\n",
        "  qini_curve_2M, qini_coeff_2M, uplift_curve_2M, auuc_2M = calculate_qini_auuc(results_2M, TARGET)\n",
        "  if qini_curve_2M is not None:\n",
        "    plot_uplift_curves(qini_curve_2M, qini_coeff_2M, uplift_curve_2M, auuc_2M, \"Two-Model\", TARGET)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOlal1PUVBkJ",
        "outputId": "37e45929-8316-4dc4-969f-43cbd8ee8cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Two-Model Approach for conversion ---\n",
            "Training set sizes: Treated=8317858, Control=1467856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # 2. Revert Label Approach\n",
        "uplift_RL, results_RL = revert_label_approach(X_train, X_test, y_train, y_test, T_train, T_test, features, TARGET)\n",
        "if results_RL is not None:\n",
        "  qini_curve_RL, qini_coeff_RL, uplift_curve_RL, auuc_RL = calculate_qini_auuc(results_RL, TARGET)\n",
        "  if qini_curve_RL is not None:\n",
        "    plot_uplift_curves(qini_curve_RL, qini_coeff_RL, uplift_curve_RL, auuc_RL, \"Revert-Label\", TARGET)\n"
      ],
      "metadata": {
        "id": "lMEx5CESVFWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}